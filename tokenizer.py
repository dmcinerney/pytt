# created from a word_model, handles indexing and vectorizing

class Tokenizer:
	pass